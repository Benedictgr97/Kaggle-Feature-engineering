{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1442 entries, 0 to 1441\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         1442 non-null   int64  \n",
      " 1   name               1442 non-null   object \n",
      " 2   location           1442 non-null   object \n",
      " 3   price              1442 non-null   object \n",
      " 4   price_for          1442 non-null   object \n",
      " 5   room_type          1442 non-null   object \n",
      " 6   beds               1434 non-null   object \n",
      " 7   rating             1394 non-null   float64\n",
      " 8   rating_title       1394 non-null   object \n",
      " 9   number_of_ratings  1394 non-null   object \n",
      " 10  url                1442 non-null   object \n",
      " 11  cm                 257 non-null    object \n",
      "dtypes: float64(1), int64(1), object(10)\n",
      "memory usage: 135.3+ KB\n"
     ]
    }
   ],
   "source": [
    "saudi_review = pd.read_csv(\"output.csv\")\n",
    "saudi_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values where no review is available as this is the metric being predicted \n",
    "saudi_review = saudi_review[saudi_review ['rating'].notna() == True].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : 864\n",
      "location : 143\n",
      "price : 351\n",
      "price_for : 2\n",
      "room_type : 250\n",
      "beds : 74\n",
      "rating_title : 6\n",
      "number_of_ratings : 756\n",
      "url : 1344\n",
      "cm : 111\n"
     ]
    }
   ],
   "source": [
    "#Basic expoloration of data \n",
    "#Drop url as all unique and no usefull features drawn from it as not very discernible.\n",
    "for i in range(0,len(saudi_review.select_dtypes(include = 'object').columns)):\n",
    "    print(saudi_review.select_dtypes(include = 'object').columns[i],':',len(saudi_review.select_dtypes(include = 'object').iloc[:,i].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the data to useable \n",
    "#Drop name as will cause data leakage if used \n",
    "saudi_review = saudi_review.drop(columns = [\"url\",\"name\",\"Unnamed: 0\",\"rating_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dammam', 'al muraysīyah', 'al olaya, riyadh', 'al qurayyat',\n",
       "       'al hamra, jeddah', 'riyadh', 'al wadeen', 'al olayya, al khobar',\n",
       "       'buraydah', 'central madinah, al madinah', 'ţurayf', 'al khobar',\n",
       "       'makkah', 'unayzah', 'al worood, riyadh', 'yanbu', 'jeddah',\n",
       "       'as suwayfilah', 'al ḩawīyah', 'al malaz, riyadh', 'sharurah',\n",
       "       'al khars', 'tanomah', 'khamis mushayt', 'az zulfi', 'al namas',\n",
       "       'al ‘awālī', 'rafha', 'rabigh', 'king abdullah economic city',\n",
       "       'riyadh al khabra', 'al rass', 'hajlah', 'al ula', 'taymāʼ',\n",
       "       'abha', 'fayfāʼ', 'waḩţān', 'al lith', 'sīdī ḩamzah', 'qabāʼ',\n",
       "       'al barkah', 'raghdān', 'ma‘shī', 'ad darb', 'bīshat mushayţ',\n",
       "       'al jāmi‘ah', 'ad dawādimī', 'as sayl aş şaghīr',\n",
       "       'al salamah, jeddah', 'tabuk', 'taif', 'al sulimania, riyadh',\n",
       "       'al madinah', 'turghush', 'hera street, jeddah', '‘urwah',\n",
       "       'madain saleh', 'sari street, jeddah', \"qal'at bishah\",\n",
       "       'al wuhayţ', 'as sudayrah', 'al jubail', 'obhor', 'al ‘azīzīyah',\n",
       "       'khumrah', 'ilbaras', 'bin hashbal', 'qurish street, jeddah',\n",
       "       'al rawda, jeddah', 'ḩaraḑ', 'al fayşalīyah', 'ash shuwaybiţ',\n",
       "       'shaqra', 'al muzāḩimīyah', 'najran', 'al ḩillah', 'al kharj',\n",
       "       'al aziziyah, riyadh', 'raʼs al khafjī', 'jazan', 'sabt alalayah',\n",
       "       'sakakah', 'al wahţ', 'hail', 'ahad rafidah', 'al madārah',\n",
       "       'al tahlia street, jeddah', 'al qunfudhah', 'al aziziyah, makkah',\n",
       "       'laylá', 'şadyān', 'ajyad, makkah', 'al bukayriyah', '‘afīf',\n",
       "       'south obhr, jeddah', 'al hada', 'umm lajj', 'hafr al baten',\n",
       "       'arar', 'sulţānah', 'raʼs munaysif', 'al aqiq', 'baljurashi',\n",
       "       'ash shuqayq', 'ash shiqqah', 'al hamra, riyadh', 'al ahsa',\n",
       "       'sawdāʼ', 'al baha', 'durat  alarous', 'buraymān',\n",
       "       'wadi al dawasir', 'al khafji', 'al shatiea, jeddah', 'şabyā',\n",
       "       'al aqrabeyah, al khobar', 'half moon bay', 'al humaizah',\n",
       "       'dawmat al jandal', 'abḩur al janūbīyah', 'ar ruʼays',\n",
       "       'al ḩanākīyah', 'al thybiyah', 'hotat bani tamim',\n",
       "       'king abdul aziz road, jeddah', 'al andalus, jeddah',\n",
       "       'palestine  street, jeddah', 'rayyis',\n",
       "       'diplomatic quarter, riyadh', 'al hofuf', 'al yarmouk, al khobar',\n",
       "       'al mikhlaf', 'al wudayy', 'al kāmil', 'baish', 'abū qa‘ar',\n",
       "       'az zahrāʼ', 'ad dār as suflá', 'şāmitah', 'al ḩalaqah',\n",
       "       'an nimāş', 'north obhr, jeddah'], dtype='<U32')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############Look into splitting up location\n",
    "location = np.array([])\n",
    "for i in range(0,saudi_review[\"location\"].nunique()):\n",
    "    location = np.append(location,saudi_review[\"location\"].unique()[i].replace(\" Show on map\",\"\").lower())\n",
    "location\n",
    "#Not usefull as can cause bias for certain locations as there is 143 unique locations for 1400 data points \n",
    "#could use Kmeans but still far to many and would skew data \n",
    "#so leakage will be most likely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        140\n",
       "1        180\n",
       "2        248\n",
       "3        250\n",
       "4        224\n",
       "        ... \n",
       "1389     285\n",
       "1390     209\n",
       "1391     150\n",
       "1392     189\n",
       "1393      81\n",
       "Name: price, Length: 1394, dtype: object"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################look into the price distribution \n",
    "saudi_review.price.apply(lambda x: x.replace(\"SAR\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only two types of strings without the Numbers showing it is all the same currency \n",
    "saudi_review['price'].str.replace('\\d+', '').unique()\n",
    "\n",
    "#change the price to a numeric useable value \n",
    "saudi_price = pd.DataFrame(pd.to_numeric(saudi_review.price.str.extract(\"(\\d*\\.?\\d+)\", expand=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################look into price for \n",
    "saudi_review.price_for.unique()\n",
    "#Only 2 outputs with 1 or 2 adults so will be split into two outputs of 1 or 2 per night ordinal encoding used to determine\n",
    "#the number of individuals staying in a room\n",
    "\n",
    "#change the number of people in a room to a usable float parameter\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder(categories=[['1 night, 1 adult', '1 night, 2 adults']])\n",
    "people_a_night = pd.DataFrame(enc.fit_transform(saudi_review[\"price_for\"].values.reshape(-1,1)) + 1,columns = ['PPN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the total number of beds from beds\n",
    "total_beds = pd.DataFrame(pd.to_numeric(saudi_review['beds'].str.split().str.get(0), errors='coerce').fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################All 3 descriptive columns \n",
    "#saudi_review.room_type.unique()\n",
    "#find usefull repetetive words that can be used to encode each type of room "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 3 most descriptive columns so dummy encoding can be used \n",
    "cols = ['room_type','cm','beds']\n",
    "saudi_review['combined'] = saudi_review[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double         1326\n",
      "1              1240\n",
      "nan            1146\n",
      "bed            1013\n",
      "room            780\n",
      "extra-large     630\n",
      "2               450\n",
      "single          368\n",
      "large           365\n",
      "beds            353\n",
      "•­              347\n",
      "apartment       298\n",
      "deluxe          232\n",
      "studio          210\n",
      "one-bedroom     210\n",
      "king            199\n",
      "standard        179\n",
      "sofa            166\n",
      "twin            159\n",
      "bathroom        152\n",
      "3               143\n",
      "double)         140\n",
      "singles, 1      138\n",
      "with            133\n",
      "suite           120\n",
      "beds\\r\\n(2      111\n",
      "private          89\n",
      "beds\\r\\n(1       87\n",
      "superior         83\n",
      "bed)             79\n",
      "bedroom          75\n",
      "or               72\n",
      "entire           72\n",
      "two-bedroom      69\n",
      "view             66\n",
      "double, 1        62\n",
      "living           61\n",
      "apartment­       59\n",
      "4                48\n",
      "budget           48\n"
     ]
    }
   ],
   "source": [
    "#Find the most used words overall to put into the encoder.\n",
    "room_str = ' '.join([str(x).lower() for x in saudi_review['combined']])\n",
    "print(pd.DataFrame(data=np.array(room_str.split(\" \")), columns=[\"col1\"])[\"col1\"].value_counts()[0:40].to_string())\n",
    "#Try top 20 to see how many values it takes to describe most locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of most used values and prune non usefull ones like bed that the model may falsely pick up on \n",
    "#Use values that cover 5% or more of hotels\n",
    "#small nuber of square meter room sizes used so not usefull \n",
    "cv_list = ['double', 'extra-large', 'large','single','apartment', 'deluxe', 'one-bedroom', 'studio',\n",
    "       'king', 'sofa', 'standard', 'twin', 'bathroom', 'double)',\n",
    "       'singles,', 'suite','private', 'superior', 'two-bedroom', 'entire',\n",
    "       'double,', 'view', 'living', 'apartment­','budget', 'economy', 'multiple', 'singles', 'city',\n",
    "       'junior', 'chalet', 'studio­', 'queen', 'suite­','family', 'triple', 'guest', 'executive', 'classic',\n",
    "       'double,', 'villa', 'single,', 'quadruple', 'singles,', 'non-smoking',\n",
    "       'double,', 'three-bedroom', 'haram', 'sea',\n",
    "       'king,','small', 'doubles)', 'garden','pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows the values to all be tunred to lower case before dummies work on the values \n",
    "zzz = saudi_review['combined'].str.lower()\n",
    "\n",
    "final_encode = (pd.get_dummies(zzz.str.split(expand=True))\n",
    "         .groupby(lambda x: x.split('_')[-1],axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce down the table to binary values and combine the same values\n",
    "#sorted(final_encode[cv_list].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce down double values \n",
    "double = ['double','double)','double,','double,','double,','doubles)']\n",
    "final_encode['double_tot'] = final_encode[double].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce single\n",
    "single = ['single','single,','singles','singles,','singles,']\n",
    "final_encode['single_tot'] = final_encode[single].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce king\n",
    "king = ['king','king,']\n",
    "final_encode['king_tot'] = final_encode[king].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce apartment\n",
    "apartment = ['apartment','apartment\\xad']\n",
    "final_encode['apartment_tot'] = final_encode[apartment].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce suite \n",
    "suite = ['suite','suite\\xad']\n",
    "final_encode['suite_tot'] = final_encode[suite].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce studio\n",
    "#'studio','studio\\xad'\n",
    "studio = ['studio','studio\\xad']\n",
    "final_encode['studio_tot'] = final_encode[studio].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final list of values \n",
    "cv_list_final = ['double_tot', 'extra-large', 'large','single_tot','apartment_tot', 'deluxe', 'one-bedroom', 'studio_tot',\n",
    "       'king_tot', 'sofa', 'standard', 'twin', 'bathroom', 'suite_tot','private', 'superior', 'two-bedroom', 'entire',\n",
    "       'view', 'living','budget', 'economy', 'multiple', 'city',\n",
    "       'junior', 'chalet', 'queen', 'family', 'triple', 'guest', 'executive', 'classic',\n",
    "       'villa', 'quadruple','non-smoking', 'three-bedroom', 'haram', 'sea','small', 'garden','pool']\n",
    "\n",
    "#Create the final dummy encoded values \n",
    "final_ohe = final_encode[cv_list_final].where(final_encode[cv_list_final] < 1, other=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start building the initial model and test performence with basic ohe\n",
    "#Pipeline not needed as pre proccesing of data was manual process \n",
    "X = pd.concat([final_ohe,total_beds,saudi_price,people_a_night],axis = 1)\n",
    "#X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = saudi_review['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XG_model = XGBRegressor(random_state = 0)\n",
    "XG_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5767564257416962\n"
     ]
    }
   ],
   "source": [
    "#mean absolute eorror from the model\n",
    "predictions = XG_model.predict(X_test)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7798505942371559\n",
      "Mean Absolute Error: 0.8057264557629501\n",
      "Mean Absolute Error: 0.6704619219401394\n",
      "Mean Absolute Error: 0.7976481032216367\n"
     ]
    }
   ],
   "source": [
    "#Find out which metrics preduce the lowest mae \n",
    "for i in [final_ohe,total_beds,saudi_price,people_a_night]:\n",
    "    #Pipeline not needed as pre proccesing of data was manual process \n",
    "    X_single = pd.concat([i],axis = 1)\n",
    "    y = saudi_review['rating']\n",
    "    \n",
    "    X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_single, y, test_size=0.33, random_state=0)\n",
    "    \n",
    "    XG_model = XGBRegressor(random_state = 0)\n",
    "    XG_model.fit(X_train_single, y_train_single)\n",
    "    \n",
    "    predictions = XG_model.predict(X_test_single)\n",
    "    print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))\n",
    "\n",
    "#Price produces the best prediction of the rating but all togethor produce the best overall prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.179869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#better than random guessing the gausian distribution \n",
    "diff = np.array([])\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    diff = np.append(diff,((y[i] - np.random.normal(7.56,1.0566396137869813))**2)**0.5)\n",
    "    \n",
    "diff = pd.DataFrame(diff)\n",
    "\n",
    "diff.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.815151\n",
       "dtype: float64"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also better than guessing the mean \n",
    "diff = np.array([])\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    diff = np.append(diff,((y[i] - 7.56)**2)**0.5)\n",
    "    \n",
    "diff = pd.DataFrame(diff)\n",
    "\n",
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineer values to increase model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull columns that can be manipulated\n",
    "#price per person per night  = price/person per night \n",
    "#price per bed = price/beds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_person = X['price']/X['PPN']\n",
    "\n",
    "price_per_person = price_per_person.rename('price_per_person')\n",
    "\n",
    "price_per_bed = X['price']/X['beds']\n",
    "price_per_bed = price_per_bed.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Some values produce infinite so correlated with price on missing values so there is no data sku from it being 0 \n",
    "ppb_to_price = pd.concat([saudi_price,pd.DataFrame(price_per_bed,columns = ['price_per_bed'])],axis = 1).dropna()\n",
    "mb = np.polyfit(ppb_to_price['price'],ppb_to_price['price_per_bed'], 1)\n",
    "for i in range(0,len(price_per_bed)):\n",
    "    if math.isnan(price_per_bed.iloc[i]):\n",
    "        price_per_bed.iloc[i] = int(mb[0] * saudi_price.iloc[i] + mb[1])\n",
    "        \n",
    "price_per_bed = price_per_bed.rename('price_per_bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5283527552176452\n"
     ]
    }
   ],
   "source": [
    "X_eng = pd.concat([final_ohe,total_beds,saudi_price,people_a_night,price_per_person,price_per_bed],axis = 1)\n",
    "y = saudi_review['rating']\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(X_eng, y, test_size=0.33, random_state=0)\n",
    "\n",
    "XG_model = XGBRegressor(random_state = 0)\n",
    "XG_model.fit(X_train_eng, y_train_eng)\n",
    "\n",
    "#mean absolute eorror from the model\n",
    "predictions = XG_model.predict(X_test_eng)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test_eng)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introducing the price per bed and person increased the model accuracy \n",
    "#overall showing feature engineering worked for this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.476078</td>\n",
       "      <td>0.144996</td>\n",
       "      <td>0.196652</td>\n",
       "      <td>-0.107158</td>\n",
       "      <td>0.122443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.199451</td>\n",
       "      <td>0.175313</td>\n",
       "      <td>0.313663</td>\n",
       "      <td>-0.150303</td>\n",
       "      <td>0.076121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000459</td>\n",
       "      <td>1.055593</td>\n",
       "      <td>0.668843</td>\n",
       "      <td>-0.148079</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.987796</td>\n",
       "      <td>1.057688</td>\n",
       "      <td>0.674213</td>\n",
       "      <td>-0.151925</td>\n",
       "      <td>0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.376309</td>\n",
       "      <td>-0.742807</td>\n",
       "      <td>0.387913</td>\n",
       "      <td>0.084804</td>\n",
       "      <td>0.017833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>0.152403</td>\n",
       "      <td>-0.749544</td>\n",
       "      <td>0.610291</td>\n",
       "      <td>0.173580</td>\n",
       "      <td>-0.049401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>-0.998897</td>\n",
       "      <td>0.197293</td>\n",
       "      <td>0.398495</td>\n",
       "      <td>-0.181582</td>\n",
       "      <td>0.042537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>-1.406921</td>\n",
       "      <td>0.152575</td>\n",
       "      <td>0.225905</td>\n",
       "      <td>-0.117944</td>\n",
       "      <td>0.110863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>-1.555676</td>\n",
       "      <td>1.778108</td>\n",
       "      <td>0.703536</td>\n",
       "      <td>0.170616</td>\n",
       "      <td>0.100112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>-1.884103</td>\n",
       "      <td>0.100278</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>-0.043521</td>\n",
       "      <td>0.190769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3       PC4       PC5\n",
       "0    -1.476078  0.144996  0.196652 -0.107158  0.122443\n",
       "1    -1.199451  0.175313  0.313663 -0.150303  0.076121\n",
       "2    -1.000459  1.055593  0.668843 -0.148079  0.012600\n",
       "3    -0.987796  1.057688  0.674213 -0.151925  0.010247\n",
       "4    -0.376309 -0.742807  0.387913  0.084804  0.017833\n",
       "...        ...       ...       ...       ...       ...\n",
       "1389  0.152403 -0.749544  0.610291  0.173580 -0.049401\n",
       "1390 -0.998897  0.197293  0.398495 -0.181582  0.042537\n",
       "1391 -1.406921  0.152575  0.225905 -0.117944  0.110863\n",
       "1392 -1.555676  1.778108  0.703536  0.170616  0.100112\n",
       "1393 -1.884103  0.100278  0.024062 -0.043521  0.190769\n",
       "\n",
       "[1394 rows x 5 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating PCA values to see if there is a mae decrease using normalised values\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "X_norm = (X_eng - X_eng.mean(axis=0)) / X_eng.std(axis=0)\n",
    "\n",
    "X_pca = pca.fit_transform(X_norm[['beds','price','PPN','price_per_person', 'price_per_bed']])\n",
    "\n",
    "# Convert to datafram\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5917738520400903\n"
     ]
    }
   ],
   "source": [
    "X_pca_tot = pd.concat([final_ohe,X_pca],axis = 1)\n",
    "y = saudi_review['rating']\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca_tot, y, test_size=0.33, random_state=0)\n",
    "\n",
    "XG_model = XGBRegressor(random_state = 0)\n",
    "XG_model.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "#mean absolute eorror from the model\n",
    "predictions = XG_model.predict(X_test_pca)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test_pca)))\n",
    "#PCA does not decrease the mean absolute error meaning values are not highly correlated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>PPN</th>\n",
       "      <th>price_per_person</th>\n",
       "      <th>price_per_bed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006225</td>\n",
       "      <td>0.077961</td>\n",
       "      <td>-0.061081</td>\n",
       "      <td>-0.400337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.006225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.183209</td>\n",
       "      <td>0.865532</td>\n",
       "      <td>0.803582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPN</th>\n",
       "      <td>0.077961</td>\n",
       "      <td>-0.183209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.572820</td>\n",
       "      <td>-0.221492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_per_person</th>\n",
       "      <td>-0.061081</td>\n",
       "      <td>0.865532</td>\n",
       "      <td>-0.572820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_per_bed</th>\n",
       "      <td>-0.400337</td>\n",
       "      <td>0.803582</td>\n",
       "      <td>-0.221492</td>\n",
       "      <td>0.760257</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      beds     price       PPN  price_per_person  \\\n",
       "beds              1.000000 -0.006225  0.077961         -0.061081   \n",
       "price            -0.006225  1.000000 -0.183209          0.865532   \n",
       "PPN               0.077961 -0.183209  1.000000         -0.572820   \n",
       "price_per_person -0.061081  0.865532 -0.572820          1.000000   \n",
       "price_per_bed    -0.400337  0.803582 -0.221492          0.760257   \n",
       "\n",
       "                  price_per_bed  \n",
       "beds                  -0.400337  \n",
       "price                  0.803582  \n",
       "PPN                   -0.221492  \n",
       "price_per_person       0.760257  \n",
       "price_per_bed          1.000000  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm[['beds','price','PPN','price_per_person', 'price_per_bed']].cov()\n",
    "#As can be seen very week correlations observed \n",
    "#only price correlations can be seen but this is already taken into account by the model as the correlations are large."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
